{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55b4912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from nptdms import TdmsFile\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ad8f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN filtering applied to single-file data.\n",
      "Filtered file saved to: /Users/shubhangchauhan/Desktop/single_file_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "file_path = \"/Users/shubhangchauhan/Desktop/Procyon Data/TaehwaV3/11_06_2025/10nmSweep1_11_06_2020_12_13 0.tdms\"\n",
    "csv_filtered_path = \"/Users/shubhangchauhan/Desktop/single_file_filtered.csv\"\n",
    "html_output_path = \"/Users/shubhangchauhan/Desktop/single_file_filtered_grid.html\"\n",
    "\n",
    "tdms_file = TdmsFile.read(file_path)\n",
    "df = tdms_file.as_dataframe()\n",
    "df.columns = df.columns.str.replace(\" \", \"_\")\n",
    "df.columns = df.columns.str.replace(\"/'Calculated_Data'/\", \"\", regex=True)\n",
    "df.columns = df.columns.str.replace(\"'\", \"\", regex=False)\n",
    "df[\"Index\"] = range(len(df))\n",
    "\n",
    "torque_centers = np.arange(0, 50, 5)\n",
    "Vdc = 51\n",
    "threshold_voltage = 0.9 * Vdc * 0.666 \n",
    "\n",
    "# Functions\n",
    "def assign_torque_group(torque):\n",
    "    if pd.isna(torque):\n",
    "        return None\n",
    "    for center in torque_centers:\n",
    "        if center - 0.2 <= torque <= center + 0.2:\n",
    "            return center\n",
    "    return None\n",
    "\n",
    "# Read and clean\n",
    "tdms_file = TdmsFile.read(file_path)\n",
    "df = tdms_file.as_dataframe()\n",
    "df.columns = df.columns.str.replace(\" \", \"_\")\n",
    "df.columns = df.columns.str.replace(f\"/'Calculated_Data'/\", \"\", regex=True)\n",
    "df.columns = df.columns.str.replace(\"'\", \"\", regex=False)\n",
    "df.EFFI1 = df.EFFI1 * 100.0\n",
    "\n",
    "# Filtering\n",
    "required_cols = [\"CAN_Id_Ref\", \"CAN_Iq_Ref\", \"Torque\", \"CAN_Vstator_V\", \"CAN_Iq_in\", \"CAN_Id_in\", \"CAN_Ld_uH\", \"CAN_Lq_uH\"]\n",
    "if not all(col in df.columns for col in required_cols):\n",
    "    raise ValueError(\"Missing required columns.\")\n",
    "\n",
    "df_filtered = df[(df[\"CAN_Id_Ref\"] != 0) & (df[\"CAN_Iq_Ref\"] != 0)]\n",
    "df_filtered = df_filtered[~((df_filtered[\"CAN_Iq_Ref\"] < 0) | (df_filtered[\"CAN_Id_Ref\"] > 0) |\n",
    "                            (df_filtered[\"CAN_Iq_in\"] < 0) | (df_filtered[\"CAN_Id_in\"] > 0))]\n",
    "\n",
    "df_filtered[\"Torque\"] = pd.to_numeric(df_filtered[\"Torque\"], errors='coerce').abs()\n",
    "df_filtered = df_filtered[~df_filtered[\"Torque\"].isna()]\n",
    "\n",
    "if \"Speed\" in df_filtered.columns:\n",
    "    df_filtered[\"Speed\"] = pd.to_numeric(df_filtered[\"Speed\"], errors='coerce').abs()\n",
    "    df_filtered = df_filtered[df_filtered[\"Speed\"] <= 3000]\n",
    "    df_filtered[\"Speed_Diff\"] = df_filtered[\"Speed\"].diff()\n",
    "    df_filtered = df_filtered[(df_filtered[\"Speed_Diff\"] == 0) | (df_filtered[\"Speed_Diff\"].isna())]\n",
    "    df_filtered.drop(columns=[\"Speed_Diff\"], inplace=True)\n",
    "\n",
    "df_filtered[\"CAN_Ld_uH\"] = pd.to_numeric(df_filtered[\"CAN_Ld_uH\"], errors=\"coerce\")\n",
    "df_filtered[\"CAN_Lq_uH\"] = pd.to_numeric(df_filtered[\"CAN_Lq_uH\"], errors=\"coerce\")\n",
    "df_filtered = df_filtered.dropna(subset=[\"CAN_Ld_uH\", \"CAN_Lq_uH\"])\n",
    "df_filtered = df_filtered[(df_filtered[\"CAN_Ld_uH\"] == 46.3) & (df_filtered[\"CAN_Lq_uH\"] == 73.48)]\n",
    "\n",
    "for col in [\"CAN_Iq_in\", \"CAN_Iq_Ref\", \"CAN_Id_in\", \"CAN_Id_Ref\"]:\n",
    "    df_filtered[col] = pd.to_numeric(df_filtered[col], errors='coerce')\n",
    "\n",
    "df_filtered = df_filtered.dropna(subset=[\"CAN_Iq_in\", \"CAN_Iq_Ref\", \"CAN_Id_in\", \"CAN_Id_Ref\"])\n",
    "df_filtered = df_filtered[\n",
    "    ((df_filtered[\"CAN_Iq_in\"] - df_filtered[\"CAN_Iq_Ref\"]).abs() <= 10) &\n",
    "    ((df_filtered[\"CAN_Id_in\"] - df_filtered[\"CAN_Id_Ref\"]).abs() <= 10)\n",
    "]\n",
    "\n",
    "if \"CAN_Bandwidth\" in df_filtered.columns:\n",
    "    df_filtered = df_filtered[df_filtered[\"CAN_Bandwidth\"] == 500]\n",
    "\n",
    "df_filtered = df_filtered[df_filtered[\"CAN_Vstator_V\"].abs() < threshold_voltage]\n",
    "df_filtered[\"Torque_Group\"] = df_filtered[\"Torque\"].apply(assign_torque_group)\n",
    "df_filtered.insert(0, \"Index\", range(1, len(df_filtered) + 1))\n",
    "\n",
    "# Compute power and efficiency before saving\n",
    "df_filtered[\"Torque\"] = pd.to_numeric(df_filtered[\"Torque\"], errors='coerce')\n",
    "df_filtered[\"Speed\"] = pd.to_numeric(df_filtered.get(\"Speed\", np.nan), errors='coerce')\n",
    "df_filtered[\"Udc4\"] = pd.to_numeric(df_filtered.get(\"Udc4\", np.nan), errors='coerce')\n",
    "df_filtered[\"Idc4\"] = pd.to_numeric(df_filtered.get(\"Idc4\", np.nan), errors='coerce')\n",
    "\n",
    "df_filtered[\"Pout\"] = df_filtered[\"Torque\"] * df_filtered[\"Speed\"] * 2 * np.pi / 60  # W\n",
    "df_filtered[\"Pin\"] = df_filtered[\"Udc4\"] * df_filtered[\"Idc4\"]  # W\n",
    "df_filtered[\"Efficiency\"] = np.where(df_filtered[\"Pin\"] != 0, df_filtered[\"Pout\"] / df_filtered[\"Pin\"], np.nan)\n",
    "\n",
    "# Remove entries where efficiency > 1\n",
    "df_filtered = df_filtered[df_filtered[\"Efficiency\"] <= 1]\n",
    "\n",
    "# --- Optional DBSCAN Filtering ---\n",
    "USE_DBSCAN_FILTER = False  # Toggle this to enable/disable DBSCAN\n",
    "\n",
    "if USE_DBSCAN_FILTER:\n",
    "    from sklearn.cluster import DBSCAN\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "    filtered_groups = []\n",
    "\n",
    "    for tg, group in df_filtered.groupby(\"Torque_Group\"):\n",
    "        if len(group) < 10:\n",
    "            continue\n",
    "\n",
    "        features = group[[\"CAN_Id_in\", \"CAN_Iq_in\"]].dropna()\n",
    "        if features.empty:\n",
    "            continue\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "        neigh = NearestNeighbors(n_neighbors=5)\n",
    "        nbrs = neigh.fit(features_scaled)\n",
    "        distances, _ = nbrs.kneighbors(features_scaled)\n",
    "        k_distances = distances[:, -1]\n",
    "\n",
    "        eps_val = max(np.percentile(k_distances, 90), 0.1)\n",
    "\n",
    "        db = DBSCAN(eps=eps_val, min_samples=5).fit(features_scaled)\n",
    "        labels = db.labels_\n",
    "\n",
    "        mask = labels != -1\n",
    "        filtered = group.loc[features.index[mask]].copy()\n",
    "        filtered_groups.append(filtered)\n",
    "\n",
    "    df_filtered = pd.concat(filtered_groups, ignore_index=True)\n",
    "    print(\"DBSCAN filtering applied to single-file data.\")\n",
    "else:\n",
    "    print(\"DBSCAN filtering skipped.\")\n",
    "\n",
    "\n",
    "# Save filtered\n",
    "df_filtered.to_csv(csv_filtered_path, index=False)\n",
    "print(f\"Filtered file saved to: {csv_filtered_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ade061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV and HTML plot.\n"
     ]
    }
   ],
   "source": [
    "df = df_filtered.copy()\n",
    "\n",
    "# List of individual variables to plot\n",
    "single_var_plots = [\"CAN_Id_in\", \"CAN_Iq_in\", \"CAN_Vstator_V\", \"CAN_Vd_Out\", \"CAN_Vq_Out\", \"CAN_Istator_A\", \"CAN_Id_Ref\",\"CAN_Iq_Ref\"]\n",
    "\n",
    "# List of pairs to overlay in one subplot: (var1, var2)\n",
    "dual_var_plots = [\n",
    "    (\"Torque\", \"Speed\") #,\n",
    "    #(\"CAN_Istator_A\", \"EFFI1\")\n",
    "]\n",
    "\n",
    "# Plotting\n",
    "total_plots = len(single_var_plots) + len(dual_var_plots)\n",
    "cols_per_row = 2\n",
    "rows = math.ceil(total_plots / cols_per_row)\n",
    "\n",
    "titles = [col for col in single_var_plots] + [f\"{a} + {b}\" for a, b in dual_var_plots]\n",
    "fig = make_subplots(\n",
    "    rows=rows,\n",
    "    cols=cols_per_row,\n",
    "    subplot_titles=titles,\n",
    "    specs=[[{\"secondary_y\": True} for _ in range(cols_per_row)] for _ in range(rows)]\n",
    ")\n",
    "\n",
    "plot_idx = 0\n",
    "\n",
    "# Plot single variable plots\n",
    "for col in single_var_plots:\n",
    "    if col in df.columns:    \n",
    "        row, col_idx = divmod(plot_idx, cols_per_row)\n",
    "        fig.add_trace(go.Scatter(x=df[\"Index\"], y=pd.to_numeric(df[col], errors=\"coerce\"),\n",
    "                                 name=col, mode=\"lines\"),\n",
    "                      row=row+1, col=col_idx+1)\n",
    "        plot_idx += 1\n",
    "\n",
    "# Plot dual variable overlays\n",
    "for var1, var2 in dual_var_plots:\n",
    "    row, col_idx = divmod(plot_idx, cols_per_row)\n",
    "    row += 1\n",
    "    col_idx += 1\n",
    "    yaxis_base = f\"y{(row - 1) * cols_per_row + col_idx}\"\n",
    "    yaxis_secondary = f\"y{(row - 1) * cols_per_row + col_idx}2\"\n",
    "\n",
    "    # Primary Y-axis trace\n",
    "    if var1 in df.columns:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df[\"Index\"],\n",
    "            y=pd.to_numeric(df[var1], errors=\"coerce\"),\n",
    "            name=var1,\n",
    "            mode=\"lines\",\n",
    "            yaxis=yaxis_base\n",
    "        ), row=row, col=col_idx,secondary_y=False)\n",
    "\n",
    "    # Secondary Y-axis trace\n",
    "    if var2 in df.columns:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df[\"Index\"],\n",
    "            y=pd.to_numeric(df[var2], errors=\"coerce\"),\n",
    "            name=var2,\n",
    "            mode=\"lines\",\n",
    "            yaxis=yaxis_secondary\n",
    "        ), row=row, col=col_idx,secondary_y=True)\n",
    "\n",
    "    fig.update_yaxes(title_text=var1, row=row, col=col_idx)\n",
    "    fig.update_yaxes(title_text=var2, row=row, col=col_idx, secondary_y=True)\n",
    "    plot_idx += 1\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    height=200 * rows,\n",
    "    width=720 * cols_per_row,\n",
    "    title=f\"Custom Data Subplots: {file_path.split('/')[-1]}\",\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Save outputs\n",
    "df_out_cols = [\"Index\"] + list(set(single_var_plots + [x for pair in dual_var_plots for x in pair]))\n",
    "df[df_out_cols].to_csv(csv_filtered_path, index=False)\n",
    "fig.write_html(html_output_path)\n",
    "\n",
    "print(\"Saved CSV and HTML plot.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "procyon_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
