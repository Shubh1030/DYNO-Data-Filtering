{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b52c7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from nptdms import TdmsFile\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c26a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "base_path = \"/Users/shubhangchauhan/Desktop/Procyon Data/TaehwaV3\"\n",
    "date_folders = [\"11_06_2025\", \"10_06_2025\"]\n",
    "\n",
    "# Flags:\n",
    "USE_DBSCAN_FILTER = True  # Set to False for no DBSCAN Filter\n",
    "USE_MTPV_ANALYSIS = True  # Set to False for MTPA\n",
    "\n",
    "# Torque and Speed grouping centers\n",
    "torque_centers = np.arange(0, 50, 5) \n",
    "speed_centers = np.arange(3000,7000,500)\n",
    "\n",
    "# Voltage threshold\n",
    "Vdc = 51\n",
    "Vmax_peak = Vdc*0.666\n",
    "threshold_voltage = 0.9 * Vmax_peak\n",
    "\n",
    "# Functions\n",
    "def assign_torque_group(torque):\n",
    "    if pd.isna(torque):\n",
    "        return None\n",
    "    for center in torque_centers:\n",
    "        if center - 0.2 <= torque <= center + 0.2:\n",
    "            return center\n",
    "    return None\n",
    "\n",
    "def assign_speed_group(speed):\n",
    "    if pd.isna(speed):\n",
    "        return None\n",
    "    for center in speed_centers:\n",
    "        if center - 20 <= speed <= center + 20:\n",
    "            return center\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49ec027d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1355 rows in 15nmSweep_11_06_2020_14_41 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 696 rows in 15nmSweep_11_06_2020_14_30 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 1580 rows in 15nmSweep_11_06_2020_15_12 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 5777 rows in AngleCalibration_11_06_2020_10_04 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 271 rows in 20nmSweep1_11_06_2020_17_57 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 8297 rows in 25nmSweep1_11_06_2020_19_17 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 15120 rows in 20nmSweep1_11_06_2020_18_44 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 23433 rows in 25nmSweep1_11_06_2020_19_40 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 6192 rows in 10nmSweep1_11_06_2020_17_04 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 1987 rows in 20nmSweep1_11_06_2020_17_28 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 19242 rows in 10nmSweep_11_06_2020_10_24 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Failed to process 20nmSweep_11_06_2020_16_06 0.tdms: Segment does not start with b'TDSm', but with b'\\x00\\x00\\x00\\x00'\n",
      "Removed 1702 rows in 15nmSweep_11_06_2020_14_16 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 7922 rows in 10nmSweep1_11_06_2020_12_13 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 250 rows in 15nmSweep_11_06_2020_15_30 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 9518 rows in AngleCalibration_11_06_2020_10_02 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 6447 rows in AngleCalibration_11_06_2020_09_59 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 593 rows in 25nmSweep1_11_06_2020_18_52 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 17972 rows in AngleCalibration_11_06_2020_09_55 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 4107 rows in 15nmSweep_11_06_2020_14_57 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 2498 rows in 15nmSweep_11_06_2020_13_41 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 7500 rows in 20nmSweep1_11_06_2020_18_31 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 11640 rows in 25nmSweep1_11_06_2020_19_29 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 1416 rows in 25nmSweep1_11_06_2020_19_16 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 601 rows in sensorcalib_11_06_2020_10_12 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 255 rows in 25nmSweep1_11_06_2020_19_08 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 848 rows in 20nmSweep1_11_06_2020_17_44 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 18318 rows in 20nmSweep1_11_06_2020_18_36 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 624 rows in 20nmSweep1_11_06_2020_17_54 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 795 rows in 15nmSweep_11_06_2020_15_48 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 370 rows in 20nmSweep1_11_06_2020_18_00 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 824 rows in 15nmSweep_11_06_2020_14_01 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 32120 rows in AngleCalibration_11_06_2020_09_48 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 4645 rows in 20nmSweep1_11_06_2020_18_08 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 1590 rows in 20nmSweep1_11_06_2020_18_04 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 9370 rows in 15nmSweep_11_06_2020_12_48 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 583 rows in 15nmSweep_11_06_2020_15_31 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 1270 rows in 15nmSweep_11_06_2020_15_40 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 9005 rows in 25nmSweep1_11_06_2020_19_24 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 3131 rows in AngleCalibration_11_06_2020_10_01 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 8711 rows in 20nmSweep1_11_06_2020_18_22 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Saved per-date grouped CSV: /Users/shubhangchauhan/Desktop/11_06_2025_torque_grouped.csv\n",
      "Removed 11357 rows in 5Nm_sweep_10_06_2020_13_26 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 20800 rows in 10Nm_sweep_10_06_2020_19_54 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 1238 rows in 5Nm_sweep_10_06_2020_13_10 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 2626 rows in 3000RPM_sweep_10_06_2020_17_26 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 21381 rows in 5Nm_sweep_10_06_2020_11_54 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 48969 rows in 5Nm_sweep_10_06_2020_11_29 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 40984 rows in 10Nm_sweep_10_06_2020_18_21 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 131 rows in 3000RPM_sweep_10_06_2020_17_45 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 26444 rows in 3000rpmspeed_10_06_2020_11_04 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 56992 rows in 5Nm_sweep_10_06_2020_12_02 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 3529 rows in 10Nm_sweep_10_06_2020_19_07 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 10961 rows in 10Nm_sweep_10_06_2020_19_21 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 1371 rows in 5Nm_sweep_10_06_2020_17_05 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 1322 rows in 5Nm_sweep_10_06_2020_14_57 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 132 rows in 5Nm_sweep_10_06_2020_16_39 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 3980 rows in 5Nm_sweep_10_06_2020_11_40 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 22414 rows in 3000RPM_sweep_10_06_2020_17_37 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 1374 rows in 5Nm_sweep_10_06_2020_14_52 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 8804 rows in 10Nm_sweep_10_06_2020_19_00 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 2372 rows in 5Nm_sweep_10_06_2020_17_12 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 2064 rows in 5Nm_sweep_10_06_2020_13_01 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 21086 rows in 3000RPM_sweep_10_06_2020_17_56 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 31327 rows in 15Nm_sweep_10_06_2020_20_04 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 16067 rows in 5Nm_sweep_10_06_2020_11_47 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 1623 rows in 5Nm_sweep_10_06_2020_16_51 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 19248 rows in 10Nm_sweep_10_06_2020_19_41 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 37929 rows in 3000rpmspeed_10_06_2020_10_52 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 8858 rows in 3000RPM_sweep_10_06_2020_17_52 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 7803 rows in 5Nm_sweep_10_06_2020_12_39 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 12359 rows in 3000RPM_sweep_10_06_2020_18_14 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 44501 rows in 5Nm_sweep_10_06_2020_11_18 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Removed 1791 rows in 5Nm_sweep_10_06_2020_14_48 0.tdms\n",
      "Filtered using columns: CAN_Id_Ref, CAN_Iq_Ref, Torque, CAN_Vstator_V, CAN_Iq_in, CAN_Id_in, CAN_Ld_uH, CAN_Lq_uH\n",
      "Saved per-date grouped CSV: /Users/shubhangchauhan/Desktop/10_06_2025_torque_grouped.csv\n"
     ]
    }
   ],
   "source": [
    "# Final collected data\n",
    "final_grouped = []\n",
    "\n",
    "for date in date_folders:\n",
    "    date_path = os.path.join(base_path, date)\n",
    "    filtered_data = []\n",
    "\n",
    "    for filename in os.listdir(date_path): \n",
    "        if filename.endswith(\".tdms\"):\n",
    "            file_path = os.path.join(date_path, filename) \n",
    "            try:\n",
    "                tdms_file = TdmsFile.read(file_path)\n",
    "                df = tdms_file.as_dataframe()\n",
    "\n",
    "                # Clean column names\n",
    "                df.columns = df.columns.str.replace(' ','_')\n",
    "                df.columns = df.columns.str.replace(f\"/'Calculated_Data'/\", \"\", regex=True)\n",
    "                df.columns = df.columns.str.replace(\"'\", \"\", regex=False)\n",
    "                df.EFFI1 = df.EFFI1 * 100.0 \n",
    "\n",
    "                # Required columns check\n",
    "                required_cols = [\"CAN_Id_Ref\", \"CAN_Iq_Ref\", \"Torque\", \"CAN_Vstator_V\",\"CAN_Iq_in\", \"CAN_Id_in\",\"CAN_Ld_uH\", \"CAN_Lq_uH\"]\n",
    "\n",
    "                if all(col in df.columns for col in required_cols):\n",
    "                    original_len = len(df)\n",
    "\n",
    "                    # Filter rows where both Id_ref and Iq_reg = 0\n",
    "                    df_filtered = df[(df[\"CAN_Id_Ref\"] != 0) & (df[\"CAN_Iq_Ref\"] != 0)]\n",
    "\n",
    "                    # Remove rows where Iq_ref < 0 OR Id_ref > 0 or Iq_in < 0 or Id_in > 0\n",
    "                    df_filtered = df_filtered[~((df_filtered[\"CAN_Iq_Ref\"] < 0) | (df_filtered[\"CAN_Id_Ref\"] > 0) | (df_filtered[\"CAN_Iq_in\"] < 0) | (df_filtered[\"CAN_Id_in\"] > 0))]\n",
    "\n",
    "                    df_filtered[\"Torque\"] = pd.to_numeric(df_filtered[\"Torque\"], errors='coerce').abs()\n",
    "                    df_filtered = df_filtered[~df_filtered[\"Torque\"].isna()]\n",
    "\n",
    "                    # Make Speed positive and filter if column exists\n",
    "                    if \"Speed\" in df_filtered.columns:\n",
    "                        df_filtered[\"Speed\"] = pd.to_numeric(df_filtered[\"Speed\"], errors='coerce').abs()\n",
    "                        if USE_MTPV_ANALYSIS:\n",
    "                            df_filtered = df_filtered[df_filtered[\"Speed\"] > 3000]\n",
    "                        else:\n",
    "                            df_filtered = df_filtered[df_filtered[\"Speed\"] <= 3000]\n",
    "\n",
    "                        # Remove rows where Speed changes between consecutive rows\n",
    "                        df_filtered[\"Speed_Diff\"] = df_filtered[\"Speed\"].diff()\n",
    "                        df_filtered = df_filtered[(df_filtered[\"Speed_Diff\"] == 0) | (df_filtered[\"Speed_Diff\"].isna())]\n",
    "                        df_filtered.drop(columns=[\"Speed_Diff\"], inplace=True)\n",
    "\n",
    "                    # Filter for specific Ld and Lq values\n",
    "                    # Ensure values are numeric\n",
    "                    df_filtered[\"CAN_Ld_uH\"] = pd.to_numeric(df_filtered[\"CAN_Ld_uH\"], errors=\"coerce\")\n",
    "                    df_filtered[\"CAN_Lq_uH\"] = pd.to_numeric(df_filtered[\"CAN_Lq_uH\"], errors=\"coerce\")\n",
    "\n",
    "                    df_filtered = df_filtered.dropna(subset=[\"CAN_Ld_uH\", \"CAN_Lq_uH\"])\n",
    "                    df_filtered = df_filtered[(df_filtered[\"CAN_Ld_uH\"] == 46.3) & (df_filtered[\"CAN_Lq_uH\"] == 73.48)]\n",
    "\n",
    "                    # Filter based on comparision\n",
    "                    for col in [\"CAN_Iq_in\", \"CAN_Iq_Ref\", \"CAN_Id_in\", \"CAN_Id_Ref\"]:\n",
    "                        df_filtered[col] = pd.to_numeric(df_filtered[col], errors='coerce')\n",
    "\n",
    "                    df_filtered = df_filtered.dropna(subset=[\"CAN_Iq_in\", \"CAN_Iq_Ref\", \"CAN_Id_in\", \"CAN_Id_Ref\"])\n",
    "                    df_filtered = df_filtered[\n",
    "                        ((df_filtered[\"CAN_Iq_in\"] - df_filtered[\"CAN_Iq_Ref\"]).abs() <= 10) &\n",
    "                        ((df_filtered[\"CAN_Id_in\"] - df_filtered[\"CAN_Id_Ref\"]).abs() <= 10)\n",
    "                    ]\n",
    "\n",
    "                    # Filter based on bandwidth\n",
    "                    if \"CAN_Bandwidth\" in df_filtered.columns:\n",
    "                        df_filtered = df_filtered[df_filtered[\"CAN_Bandwidth\"] == 500]\n",
    "\n",
    "                    rows_removed = original_len - len(df_filtered)\n",
    "                    if rows_removed > 0:\n",
    "                        print(f\"Removed {rows_removed} rows in {filename}\")\n",
    "\n",
    "                    df_filtered[\"source_file\"] = filename\n",
    "                    filtered_data.append(df_filtered)\n",
    "                    print(f\"Filtered using columns: {', '.join(required_cols)}\")\n",
    "                else:\n",
    "                    print(f\"Required columns not found in {filename}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {filename}: {e}\")\n",
    "\n",
    "    if filtered_data:\n",
    "        combined_df = pd.concat(filtered_data, ignore_index=True)\n",
    "\n",
    "        # Group and classify\n",
    "        combined_df[\"Torque_Group\"] = combined_df[\"Torque\"].apply(assign_torque_group)\n",
    "        if USE_MTPV_ANALYSIS:\n",
    "            combined_df[\"Speed_Group\"] = combined_df[\"Speed\"].apply(assign_speed_group)\n",
    "\n",
    "        # MTPA vs MTPV Filtering \n",
    "        if USE_MTPV_ANALYSIS:\n",
    "            combined_df = combined_df[combined_df[\"CAN_Vstator_V\"].abs() > threshold_voltage]\n",
    "        else:\n",
    "            combined_df = combined_df[combined_df[\"CAN_Vstator_V\"].abs() < threshold_voltage]\n",
    "\n",
    "        combined_df = combined_df.sort_values(by=[\"Torque_Group\", \"Torque\", \"CAN_Vstator_V\"])\n",
    "        combined_df.insert(0, \"Index\", range(1, len(combined_df) + 1))\n",
    "\n",
    "        # Compute Pout, Pin, Efficiency, and Filter Efficiency > 1 \n",
    "        combined_df[\"Torque\"] = pd.to_numeric(combined_df[\"Torque\"], errors='coerce')\n",
    "        combined_df[\"Speed\"] = pd.to_numeric(combined_df.get(\"Speed\", np.nan), errors='coerce')\n",
    "        combined_df[\"Udc4\"] = pd.to_numeric(combined_df.get(\"Udc4\", np.nan), errors='coerce')\n",
    "        combined_df[\"Idc4\"] = pd.to_numeric(combined_df.get(\"Idc4\", np.nan), errors='coerce')\n",
    "\n",
    "        combined_df[\"Pout\"] = combined_df[\"Torque\"] * combined_df[\"Speed\"] * 2 * np.pi / 60\n",
    "        combined_df[\"Pin\"] = combined_df[\"Udc4\"] * combined_df[\"Idc4\"]\n",
    "        combined_df[\"Efficiency\"] = np.where(combined_df[\"Pin\"] != 0, combined_df[\"Pout\"] / combined_df[\"Pin\"], np.nan)\n",
    "\n",
    "        combined_df[\"Efficiency\"] = combined_df[\"Efficiency\"].abs()\n",
    "        combined_df = combined_df[(combined_df[\"Efficiency\"] <= 1) & combined_df[\"Efficiency\"].notna() & np.isfinite(combined_df[\"Efficiency\"])]\n",
    "\n",
    "        if USE_MTPV_ANALYSIS:\n",
    "            combined_df[\"CAN_Vstator_V\"] = pd.to_numeric(combined_df[\"CAN_Vstator_V\"], errors=\"coerce\")\n",
    "            combined_df[\"Torque_per_Volt\"] = np.where(combined_df[\"CAN_Vstator_V\"] != 0,combined_df[\"Torque\"] / combined_df[\"CAN_Vstator_V\"],np.nan)\n",
    "        elif \"CAN_Istator_A\" in combined_df.columns:\n",
    "            combined_df[\"CAN_Istator_A\"] = pd.to_numeric(combined_df[\"CAN_Istator_A\"], errors=\"coerce\")\n",
    "            combined_df[\"Torque_per_Amp\"] = np.where(combined_df[\"CAN_Istator_A\"] != 0,combined_df[\"Torque\"] / combined_df[\"CAN_Istator_A\"],np.nan)\n",
    "        else:\n",
    "            print(f\"Missing required columns for MTPA/MTPV calculation in {date}\")\n",
    "\n",
    "        # Save per-date grouped CSV\n",
    "        grouped_csv_path = f\"/Users/shubhangchauhan/Desktop/{date}_torque_grouped.csv\"\n",
    "        combined_df.to_csv(grouped_csv_path, index=False)\n",
    "        print(f\"Saved per-date grouped CSV: {grouped_csv_path}\")\n",
    "\n",
    "        final_grouped.append(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e40f81a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive DBSCAN filtering applied for Iq_in vs Id_in by Torque group.\n",
      "Final grouped CSV saved: /Users/shubhangchauhan/Desktop/torque_mtpa_mtpv_all_data.csv\n",
      "Torque_Group\n",
      "5.0             73918\n",
      "NaN             44415\n",
      "10.0             4081\n",
      "15.0             1147\n",
      "20.0               93\n",
      "25.0               56\n",
      "0.0                 5\n",
      "Name: count, dtype: int64\n",
      "Saved MTPV.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v0/1ff0mzw97jj43_fqmljwhq9w0000gn/T/ipykernel_1377/3967856877.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tv_valid[\"Torque_per_Volt\"] = pd.to_numeric(tv_valid[\"Torque_per_Volt\"], errors=\"coerce\")\n"
     ]
    }
   ],
   "source": [
    "# Combine all data\n",
    "if final_grouped:\n",
    "    all_grouped_df = pd.concat(final_grouped, ignore_index=True)\n",
    "    all_grouped_df.drop(columns=[\"Index\"], inplace=True, errors='ignore')\n",
    "    all_grouped_df.insert(0, \"Index\", range(1, len(all_grouped_df) + 1))\n",
    "\n",
    "    # Adaptive DBSCAN filtering\n",
    "    filtered_groups = []\n",
    "\n",
    "    for tg, group in all_grouped_df.groupby(\"Torque_Group\"):\n",
    "        if len(group) < 10:\n",
    "            continue\n",
    "\n",
    "        features = group[[\"CAN_Id_in\", \"CAN_Iq_in\"]].dropna()\n",
    "        if features.empty:\n",
    "            continue\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "        neigh = NearestNeighbors(n_neighbors=5)\n",
    "        nbrs = neigh.fit(features_scaled)\n",
    "        distances, _ = nbrs.kneighbors(features_scaled)\n",
    "        k_distances = distances[:, -1]\n",
    "    \n",
    "        #eps_val = np.percentile(k_distances, 90)\n",
    "        eps_val = max(np.percentile(k_distances, 90), 0.1)\n",
    "\n",
    "\n",
    "        db = DBSCAN(eps=eps_val, min_samples=5).fit(features_scaled)\n",
    "        labels = db.labels_\n",
    "\n",
    "        mask = labels != -1\n",
    "        filtered = group.loc[features.index[mask]].copy()\n",
    "        filtered_groups.append(filtered)\n",
    "\n",
    "    all_grouped_df_dbscan = pd.concat(filtered_groups, ignore_index=True)\n",
    "    print(\"Adaptive DBSCAN filtering applied for Iq_in vs Id_in by Torque group.\")\n",
    "\n",
    "\n",
    "   # Choose dataset based on DBSCAN flag\n",
    "    final_df = all_grouped_df_dbscan if USE_DBSCAN_FILTER else all_grouped_df\n",
    "    final_csv_path = \"/Users/shubhangchauhan/Desktop/torque_mtpa_mtpv_all_data.csv\"\n",
    "    final_df.to_csv(final_csv_path, index=False)\n",
    "    print(f\"Final grouped CSV saved: {final_csv_path}\")\n",
    "\n",
    "    print(all_grouped_df[[\"Torque_Group\"]].value_counts(dropna=False))\n",
    "\n",
    "    #  Create a dataframe for max Torque_per_Amp/ Torque_per_volt per group\n",
    "    if final_df is not None and USE_MTPV_ANALYSIS:\n",
    "        tv_valid = final_df.dropna(subset=[\"Torque_Group\", \"Speed_Group\", \"Torque_per_Volt\"])\n",
    "        tv_valid[\"Torque_per_Volt\"] = pd.to_numeric(tv_valid[\"Torque_per_Volt\"], errors=\"coerce\")\n",
    "        max_indices = (tv_valid.groupby([\"Torque_Group\", \"Speed_Group\"])[\"Torque_per_Volt\"].idxmax().dropna())\n",
    "        MTPV_df = final_df.loc[max_indices].sort_values([\"Torque_Group\", \"Speed_Group\"]).reset_index(drop=True)\n",
    "        MTPV_df.to_csv(\"/Users/shubhangchauhan/Desktop/MTPV.csv\", index=False)\n",
    "        print(\"Saved MTPV.csv\")\n",
    "\n",
    "    elif \"Torque_per_Amp\" in final_df.columns:\n",
    "        tpa_valid = final_df.dropna(subset=[\"Torque_Group\", \"Torque_per_Amp\"])\n",
    "        tpa_valid[\"Torque_per_Amp\"] = pd.to_numeric(tpa_valid[\"Torque_per_Amp\"], errors=\"coerce\")\n",
    "        max_indices = tpa_valid.groupby(\"Torque_Group\")[\"Torque_per_Amp\"].idxmax()\n",
    "        MTPA_df = final_df.loc[max_indices].sort_values(\"Torque_Group\").reset_index(drop=True)\n",
    "        MTPA_df.to_csv(\"/Users/shubhangchauhan/Desktop/MTPA.csv\", index=False)\n",
    "        print(\" Saved MTPA.csv\")\n",
    "    else:\n",
    "        print(\"Required columns missing for Torque efficiency filtering.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78e624c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots saved as HTML.\n"
     ]
    }
   ],
   "source": [
    "# Plots\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# Torque vs Speed Scatter with hover info #####\n",
    "fig1 = px.scatter(\n",
    "    all_grouped_df,\n",
    "    x=\"Speed\",\n",
    "    y=\"Torque\",\n",
    "    hover_data={\n",
    "        \"Speed\": False,\n",
    "        \"Torque\": False,\n",
    "        \"CAN_Id_in\": True,\n",
    "        \"CAN_Iq_in\": True\n",
    "    },\n",
    "    labels={\"Speed\": \"Speed (RPM)\", \"Torque\": \"Torque (Nm)\"},\n",
    "    title=\"Torque vs Speed\"\n",
    ")\n",
    "fig1.update_traces(\n",
    "    hovertemplate=\"<br>\".join([\n",
    "        \"Speed (RPM): %{x}\",\n",
    "        \"Torque (Nm): %{y}\",\n",
    "        \"Id (A): %{customdata[0]}\",\n",
    "        \"Iq (A): %{customdata[1]}\"\n",
    "    ])\n",
    ")\n",
    "pio.write_html(fig1, file=\"/Users/shubhangchauhan/Desktop/torque_speed_plot.html\", auto_open=False)\n",
    "\n",
    "# Iq_in vs Id_in Scatter ########\n",
    "fig2 = px.scatter(\n",
    "    all_grouped_df,\n",
    "    x=\"CAN_Id_in\",\n",
    "    y=\"CAN_Iq_in\",\n",
    "    title=\"Iq_in vs Id_in\",\n",
    "    hover_data={\n",
    "        \"Speed\": True,\n",
    "        \"Torque\": True,\n",
    "        \"CAN_Id_in\": True,\n",
    "        \"CAN_Iq_in\": True\n",
    "    },\n",
    "    labels={\"CAN_Id_in\": \"Id_in (A)\", \"CAN_Iq_in\": \"Iq_in (A)\"}\n",
    ")\n",
    "pio.write_html(fig2, file=\"/Users/shubhangchauhan/Desktop/iq_id_plot.html\", auto_open=False)\n",
    "\n",
    "\n",
    "# Iq_in vs Id_in with torque group for MTPA/MTPV ######\n",
    "\n",
    "df_plot = final_df.dropna(subset=[\"Torque_Group\", \"CAN_Id_in\", \"CAN_Iq_in\"]).copy() \n",
    "min_points = MTPV_df.copy() if USE_MTPV_ANALYSIS else MTPA_df.copy()\n",
    "\n",
    "# Base scatter plot\n",
    "fig = px.scatter(\n",
    "    df_plot,\n",
    "    x=\"CAN_Id_in\",\n",
    "    y=\"CAN_Iq_in\",\n",
    "    color=\"Torque_Group\",\n",
    "    title=\"Iq_in vs Id_in by Torque Group\",\n",
    "    labels={\"CAN_Id_in\": \"Id_in (A)\", \"CAN_Iq_in\": \"Iq_in (A)\", \"Torque_Group\": \"Torque Group (Nm)\"},\n",
    "    opacity=0.3,\n",
    "    hover_data={\n",
    "        \"Speed\": True,\n",
    "        \"Torque\": True,\n",
    "        \"CAN_Id_in\": True,\n",
    "        \"CAN_Iq_in\": True\n",
    "    }\n",
    "    #color_continuous_scale=\"Viridis\"\n",
    ")\n",
    "\n",
    "point_label = \"MTPV point\" if USE_MTPV_ANALYSIS else \"MTPA point\"\n",
    "# Add 'X' markers for min points\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=min_points[\"CAN_Id_in\"],\n",
    "    y=min_points[\"CAN_Iq_in\"],\n",
    "    mode='markers+text',\n",
    "    text=[point_label]*len(min_points),\n",
    "    textposition=\"top center\",\n",
    "    name=f\"{point_label}s\",\n",
    "    marker=dict(\n",
    "        symbol=\"x\",\n",
    "        size=12,\n",
    "        color=\"black\",\n",
    "        line=dict(width=2, color=\"white\")\n",
    "    ),\n",
    "    showlegend=True\n",
    "))\n",
    "\n",
    "# Create a summary text\n",
    "if USE_MTPV_ANALYSIS:\n",
    "    summary_lines = [\n",
    "        f\"Torque {row['Torque_Group']:.1f} Nm → T/Vₛ = {row['Torque_per_Volt']:.2f} Nm/V\"\n",
    "        for _, row in min_points.iterrows()\n",
    "    ]\n",
    "else:\n",
    "    summary_lines = [\n",
    "        f\"Torque {row['Torque_Group']:.1f} Nm → T/Iₛ = {row['Torque_per_Amp']:.2f} Nm/A\"\n",
    "        for _, row in min_points.iterrows()\n",
    "    ]\n",
    "summary_text = \"<br>\".join(summary_lines)\n",
    "\n",
    "# Add annotation box\n",
    "fig.add_annotation(\n",
    "    text=summary_text,\n",
    "    align=\"left\",\n",
    "    showarrow=False,\n",
    "    xref=\"paper\", yref=\"paper\",\n",
    "    x=1, y=1, \n",
    "    bordercolor=\"black\",\n",
    "    borderwidth=1,\n",
    "    bgcolor=\"white\",\n",
    "    font=dict(size=12),\n",
    ")\n",
    "\n",
    "output_path = \"/Users/shubhangchauhan/Desktop/iq_vs_id_torque_colored.html\"\n",
    "fig.write_html(output_path)\n",
    "\n",
    "# # Iq vs Id for a torque group #######\n",
    "# df_torque5 = final_df[all_grouped_df[\"Torque_Group\"] == 5].dropna(subset=[\"CAN_Id_in\", \"CAN_Iq_in\"]) \n",
    "\n",
    "# fig = px.scatter(\n",
    "#     df_torque5,\n",
    "#     x=\"CAN_Id_in\",\n",
    "#     y=\"CAN_Iq_in\",\n",
    "#     title=\"Iq_in vs Id_in (Torque Group = 5 Nm)\",\n",
    "#     labels={\"CAN_Id_in\": \"Id_in (A)\", \"CAN_Iq_in\": \"Iq_in (A)\"},\n",
    "#     opacity=0.7,\n",
    "#     hover_data={\n",
    "#         \"CAN_Id_in\": True,\n",
    "#         \"CAN_Iq_in\": True,\n",
    "#         \"CAN_Vstator_V\": True,\n",
    "#         \"CAN_Istator_A\": True\n",
    "#     }\n",
    "# )\n",
    "# plot_path = \"/Users/shubhangchauhan/Desktop/iq_vs_id_torque_5nm.html\"\n",
    "# fig.write_html(plot_path)\n",
    "\n",
    "# Contour Plot Torque vs Speed ########\n",
    "df_plot = all_grouped_df_dbscan.copy() if USE_DBSCAN_FILTER else all_grouped_df.copy()\n",
    "\n",
    "# Drop rows with missing or invalid values\n",
    "df_plot = df_plot.dropna(subset=[\"Torque\", \"Speed\", \"Efficiency\"]).copy()\n",
    "\n",
    "# Convert to percent and filter\n",
    "df_plot[\"Efficiency(%)\"] = df_plot[\"Efficiency\"] * 100\n",
    "df_plot = df_plot[(df_plot[\"Efficiency(%)\"] > 0) & (df_plot[\"Efficiency(%)\"] <= 100)]\n",
    "\n",
    "# Extract x, y, z\n",
    "x = df_plot[\"Speed\"].values\n",
    "y = df_plot[\"Torque\"].values\n",
    "z = df_plot[\"Efficiency(%)\"].values\n",
    "\n",
    "# Define a regular grid to interpolate over\n",
    "xi = np.linspace(np.min(x), np.max(x), 300)\n",
    "yi = np.linspace(np.min(y), np.max(y), 300)\n",
    "xi_grid, yi_grid = np.meshgrid(xi, yi)\n",
    "\n",
    "# Interpolate using linear method to avoid wild spikes\n",
    "zi = griddata((x, y), z, (xi_grid, yi_grid), method='linear')\n",
    "\n",
    "# Remove NaNs to avoid plotting garbage\n",
    "zi = np.nan_to_num(zi, nan=0)\n",
    "\n",
    "# Create contour plot\n",
    "fig_contour = go.Figure(data=go.Contour(\n",
    "    z=zi,\n",
    "    x=xi,\n",
    "    y=yi,\n",
    "    colorscale='Viridis',\n",
    "    contours=dict(\n",
    "        coloring=\"heatmap\",\n",
    "        showlabels=True,\n",
    "        labelfont=dict(size=10, color='white')\n",
    "    ),\n",
    "    colorbar=dict(title=\"Efficiency (%)\")\n",
    "))\n",
    "\n",
    "fig_contour.update_layout(\n",
    "    title=\"Efficiency Contour Plot: Torque vs Speed\",\n",
    "    xaxis_title=\"Speed (RPM)\",\n",
    "    yaxis_title=\"Torque (Nm)\",\n",
    "    width=1200,\n",
    "    height=800\n",
    ")\n",
    "\n",
    "# Save to HTML\n",
    "contour_output_path = \"/Users/shubhangchauhan/Desktop/efficiency_contour_plot.html\"\n",
    "fig_contour.write_html(contour_output_path)\n",
    "\n",
    "print(\"Plots saved as HTML.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "procyon_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
